# VPR Chess Engine

**VPR** - A revolutionary piece-focused chess engine that thinks like a human player, analyzing pieces and their opportunities rather than exhaustively searching moves.

> *"Think like a human, not a machine"*

## üöÄ VPR v7.0 - Revolutionary Update (Current Version)

**VPR v7.0** represents a complete architectural transformation from the original stripped-down engine to a revolutionary **piece-centric approach** that mimics human chess thinking patterns.

### What's New in v7.0:

#### üß† **Human-Like Thinking Architecture**
- **Piece-Focused Analysis**: Engine analyzes each piece's opportunities rather than exhaustively searching all moves
- **Dynamic Piece Potential**: No static piece values - pieces are evaluated based on their current position and tactical opportunities
- **Priority-Based Evaluation**: Pieces receive priority scores (0-3000+) based on threats, opportunities, and tactical importance

#### üéØ **Tactical Awareness System**
- **Threat Detection**: Automatically identifies pieces under attack with high priority (2000+ priority)
- **Opportunity Recognition**: Spots tactical patterns like forks, pins, and checks
- **Emergency Response**: Critical threats get immediate attention in move selection

#### ‚ö° **Revolutionary Search Method**
```python
# Traditional engines: "What moves are available from this position?"
for move in all_legal_moves:
    evaluate_move(move)

# VPR v7.0: "What can each piece accomplish?"
for piece in active_pieces:
    analyze_opportunities(piece)
    generate_piece_moves(piece)
```

#### üìä **Dynamic Evaluation Features**
- **Position-Based Scoring**: Pieces scored by contribution to current position
- **Tactical Pattern Recognition**: Bonus points for pieces creating tactical threats
- **Human-Priority Scoring**: 
  - EMERGENCY (2500+): Pieces under immediate attack
  - URGENT (2000-2499): Critical tactical opportunities
  - HIGH (1500-1999): Important strategic pieces
  - NORMAL (1000-1499): Active pieces
  - LOW (500-999): Passive pieces

### Performance Comparison (v7.0 vs V7P3R v12.6):

| Metric | VPR v7.0 | V7P3R v12.6 | Notes |
|--------|----------|-------------|-------|
| **Thinking Style** | Piece-focused | Move-focused | VPR analyzes like humans |
| **Evaluation** | Dynamic potential | Static + heuristics | No fixed piece values |
| **Endgame Performance** | Superior | Struggled | VPR: 8 ply, V7P3R: 0 ply |
| **Tactical Recognition** | Priority-based | Pattern-based | Different approach |
| **NPS (Complex)** | 1,201 | 1,793 | V7P3R faster raw search |
| **Architecture** | Revolutionary | Traditional | Completely different paradigm |

---

## üìã VPR v1.0 (Legacy) - Original Minimal Engine

*The sections below describe the original VPR v1.0 concept - a minimal engine focused on raw search speed.*

## Quick Stats (VPR v7.0)

- **Architecture**: Piece-centric human-like thinking
- **Evaluation**: 100% dynamic piece potential (no static values)
- **Tactical Awareness**: Priority-based threat detection (0-3000+ scale)
- **Search Method**: Piece-focused opportunity analysis
- **Code Philosophy**: "Analyze pieces, not positions"
- **Unique Feature**: First engine to eliminate static piece values entirely

## Legacy Stats (VPR v1.0)

- **Nodes Searched**: 10x more than V7P3R
- **Search Speed**: 5x faster NPS (17,000+ vs 4,000)
- **Code Size**: 400 lines (vs 2,600 in V7P3R)
- **Search Depth**: +1-2 plies deeper in same time
- **Evaluation**: Material + Piece-Square Tables only

## What is VPR?

### VPR v7.0 (Current) - The Human-Thinking Engine

VPR v7.0 is a revolutionary chess engine that **thinks like a human chess player**. Instead of exhaustively searching all possible moves, VPR analyzes each piece individually to understand:

- What threats is this piece facing?
- What tactical opportunities can this piece create?
- How does this piece contribute to the overall position?
- What are the most important pieces right now?

This approach creates an engine that **prioritizes like a human** - focusing on the most critical pieces and threats first, rather than treating all moves equally.

**Key Innovation**: VPR v7.0 is the first chess engine to completely eliminate static piece values, using 100% dynamic evaluation based on position and tactical context.

### VPR v1.0 (Legacy) - The Speed Engine

The original VPR was an experimental chess engine built on one principle: **raw search depth beats sophisticated evaluation** (sometimes). By removing 80% of V7P3R's features, VPR v1.0 achieved 10x node throughput at the cost of positional understanding.

### What VPR v7.0 Has

‚úÖ **Revolutionary piece-focused search**  
‚úÖ **Dynamic piece potential evaluation**  
‚úÖ **Human-like tactical prioritization**  
‚úÖ **Threat detection and response system**  
‚úÖ **Zero static piece values (100% dynamic)**  
‚úÖ **Priority-based move ordering**  
‚úÖ **Piece opportunity analysis**  
‚úÖ **UCI protocol support**  
‚úÖ **Time management**  

### What VPR v7.0 Doesn't Have

‚ùå **Traditional move-first search**  
‚ùå **Static piece-square tables**  
‚ùå **Fixed piece values**  
‚ùå **Transposition table** (yet)  
‚ùå **Quiescence search** (yet)  
‚ùå **Opening book**  
‚ùå **Endgame tablebase**  

### What VPR v1.0 Had (Legacy)

‚úÖ Alpha-beta negamax search  
‚úÖ Iterative deepening  
‚úÖ Basic move ordering (MVV-LVA)  
‚úÖ Material evaluation  
‚úÖ Piece-square tables  
‚úÖ Time management  
‚úÖ UCI protocol support  

### What VPR v1.0 Didn't Have (Legacy)

‚ùå Transposition table  
‚ùå Killer moves / history heuristic  
‚ùå Quiescence search  
‚ùå Advanced pawn evaluation  
‚ùå King safety evaluation  
‚ùå Tactical pattern detection  
‚ùå PV following  
‚ùå Nudge system  
‚ùå Evaluation caching  

## Performance Results

Benchmark on 5 test positions (3 second time limit):

| Position | VPR Nodes | V7P3R Nodes | Improvement |
|----------|-----------|-------------|-------------|
| Starting position | 39,754 | 5,323 | **7.47x** |
| Italian middlegame | 36,092 | 8,120 | **4.44x** |
| Center tension | 36,721 | 26,750 | **1.37x** |
| K+P endgame | 75,394 | 2,155 | **34.99x** üî• |
| Complex middlegame | 39,334 | 11,439 | **3.44x** |

**Average**: 10.34x more nodes, 5.24x higher NPS

## Installation

### Requirements
- Python 3.8+
- python-chess library

```bash
pip install python-chess==1.999
```

### Running VPR

```bash
# UCI interface (for GUIs)
python src/vpr_uci.py

# Direct Python usage
python -c "
from src.vpr import VPREngine
import chess
engine = VPREngine()
move = engine.search(chess.Board(), time_limit=3.0)
print(f'Best move: {move}')
"
```

### Running Performance Tests

```bash
# Compare VPR vs V7P3R
python testing/test_vpr_comparison.py
```

## Usage Examples

### 1. UCI Interface (Arena, Cutechess, etc.)

```
uci
uciok
id name VPR v1.0
id author Pat Snyder

position startpos moves e2e4 e7e5
go movetime 3000

info depth 4 score cp 25 nodes 15000 time 1500 nps 10000 pv g1f3
bestmove g1f3
```

### 2. Python Integration

```python
from src.vpr import VPREngine
import chess

# Create engine
engine = VPREngine()

# Search a position
board = chess.Board()
best_move = engine.search(board, time_limit=5.0)

# Get engine info
info = engine.get_engine_info()
print(f"Searched {info['nodes_searched']} nodes")

# New game
engine.new_game()
```

### 3. Custom Time Controls

```python
# Fixed depth search
move = engine.search(board, depth=6)

# Time-based search
move = engine.search(board, time_limit=10.0)
```

## When to Use VPR

### ‚úÖ Good Use Cases

- **Tactical Puzzles**: Deep calculation reveals solution
- **Endgames**: Simple evaluation sufficient (34x speedup!)
- **Feature Testing**: Measure impact of individual features
- **Learning**: Clean, simple engine architecture
- **Speed Chess**: Fast NPS important
- **Depth-Critical Positions**: Extra plies reveal winning move

### ‚ùå Poor Use Cases

- **Opening Phase**: Weak positional understanding
- **Strategic Positions**: Can't evaluate complex plans
- **King Attacks**: No king safety evaluation
- **Rated Games**: Less stable than full engine
- **Positional Endgames**: Weak pawn structure understanding

## Architecture

### File Structure

```
src/
‚îú‚îÄ‚îÄ vpr.py           (~600 lines) - Main v7.0 engine with piece-focused thinking
‚îî‚îÄ‚îÄ vpr_uci.py       (~150 lines) - UCI interface

builds/
‚îú‚îÄ‚îÄ VPR_v1.0/        - Legacy minimal engine
‚îú‚îÄ‚îÄ VPR_v2.0/        - Evolution steps
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ VPR_v6.0/        - Pre-revolution versions

testing/
‚îú‚îÄ‚îÄ engine_comparison.py     - VPR vs V7P3R comparison
‚îú‚îÄ‚îÄ test_dynamic_potential.py - Dynamic evaluation tests
‚îú‚îÄ‚îÄ test_piece_focused.py    - Piece-centric search tests
‚îî‚îÄ‚îÄ test_tuned_scoring.py    - Priority system tests

docs/
‚îî‚îÄ‚îÄ VPR_Design_Document.md - Detailed design doc
```

### Core Algorithm (VPR v7.0)

```python
def search(board, time_limit):
    """Human-like piece-focused search"""
    # Analyze each piece's potential and opportunities
    piece_priorities = self._analyze_all_pieces(board)
    
    # Generate moves based on piece importance
    candidate_moves = self._generate_piece_focused_moves(board, piece_priorities)
    
    # Search with piece-priority ordering
    return self._iterative_deepening(board, candidate_moves, time_limit)

def _analyze_piece_opportunities(self, board, piece, square):
    """Analyze what this piece can accomplish"""
    priority = 1000  # Base priority
    
    # Check for threats (EMERGENCY level)
    if self._is_piece_attacked(board, square):
        priority += 1500  # Under attack!
    
    # Check for tactical opportunities
    opportunities = self._find_tactical_patterns(board, piece, square)
    priority += len(opportunities) * 200
    
    # Positional contribution
    priority += self._calculate_piece_potential(board, piece, square)
    
    return priority

def _calculate_piece_potential(self, board, piece, square):
    """Dynamic evaluation - no static piece values!"""
    potential = 0
    
    # Mobility and control
    controlled_squares = len(list(board.attacks(square)))
    potential += controlled_squares * 10
    
    # Central control bonus
    if square in chess.SquareSet(chess.parse_square('d4'), chess.parse_square('d5'), 
                                chess.parse_square('e4'), chess.parse_square('e5')):
        potential += 50
    
    # Tactical threats created
    potential += self._count_threats_created(board, piece, square) * 100
    
    return potential
```

### Legacy Core Algorithm (VPR v1.0)

```python
def search(board, time_limit):
    # Iterative deepening from depth 1..8
    for depth in range(1, 9):
        for move in legal_moves:
            score = -negamax(board, depth-1, -‚àû, +‚àû)
            # Track best move
        # Return if time exceeded

def negamax(board, depth, alpha, beta):
    if depth == 0:
        return evaluate(board)  # Material + PST
    
    for move in ordered_moves():  # Captures first (MVV-LVA)
        score = -negamax(board, depth-1, -beta, -alpha)
        alpha = max(alpha, score)
        if alpha >= beta:
            break  # Cutoff
    
    return alpha
```

### Evaluation Function

#### VPR v7.0 - Dynamic Piece Potential (Current)

```python
def evaluate(board):
    """Revolutionary: No static piece values!"""
    total_potential = 0
    
    for square, piece in board.piece_map().items():
        if piece.color == board.turn:
            # Dynamic potential based on position and threats
            potential = self._calculate_piece_potential(board, piece, square)
            
            # Priority bonuses for tactical importance
            priority = self._analyze_piece_opportunities(board, piece, square)
            
            # Combine potential and priority
            piece_value = potential * (priority / 1000.0)
            total_potential += piece_value
        else:
            # Opponent pieces reduce our evaluation
            opponent_potential = self._calculate_piece_potential(board, piece, square)
            total_potential -= opponent_potential
    
    return total_potential  # 100% dynamic evaluation

def _calculate_piece_potential(self, board, piece, square):
    """No piece_values dictionary - everything is contextual!"""
    base_potential = {
        chess.PAWN: 100, chess.KNIGHT: 320, chess.BISHOP: 330,
        chess.ROOK: 500, chess.QUEEN: 900, chess.KING: 0
    }[piece.piece_type]
    
    # Modify based on actual position value
    mobility = len(list(board.attacks(square))) * 10
    center_bonus = 50 if square in CENTER_SQUARES else 0
    threat_bonus = self._count_threats_created(board, piece, square) * 100
    
    return base_potential + mobility + center_bonus + threat_bonus
```

#### VPR v1.0 - Static Evaluation (Legacy)

```python
def evaluate(board):
    score = 0
    for piece in board:
        # Material value
        score += PIECE_VALUES[piece.type]
        
        # Position value (piece-square table)
        score += PST[piece.type][piece.square]
    
    return score  # From current player's perspective
```

**Revolutionary Difference**: VPR v7.0 has **NO** `PIECE_VALUES` dictionary! Every piece is evaluated dynamically based on what it can actually accomplish in the current position.

## Configuration

VPR has minimal configuration (by design):

```python
# In vpr.py __init__()
self.default_depth = 8  # Maximum search depth
self.piece_values = {   # Standard piece values
    PAWN: 100, KNIGHT: 320, BISHOP: 330,
    ROOK: 500, QUEEN: 900
}
```

Piece-square tables can be tuned in `_init_piece_square_tables()`.

## Comparison with V7P3R

| Feature | VPR v7.0 (Current) | VPR v1.0 (Legacy) | V7P3R v12.x |
|---------|---------------------|-------------------|-------------|
| **Architecture** | Piece-focused thinking | Move-focused minimal | Traditional full-featured |
| **Lines of Code** | ~600 | ~400 | ~2,600 |
| **Evaluation** | 100% dynamic potential | Material + PST | 9 components |
| **Piece Values** | None (dynamic only) | Static dictionary | Static + bonuses |
| **Search Method** | Piece opportunities | Raw negamax | Advanced pruning |
| **Tactical Awareness** | Priority-based (0-3000) | None | Pattern-based |
| **Move Ordering** | Piece-priority focused | MVV-LVA only | TT + Killers + History |
| **Thinking Style** | Human-like analysis | Brute force | Computer optimization |
| **Nodes/Second** | 1,201 (complex pos) | 17,677 | 1,793 |
| **Search Depth** | 2-3 ply | 4-7 ply | 3-4 ply |
| **Endgame Performance** | Superior (8 ply) | Fast but weak | Struggled (0 ply) |
| **Innovation Level** | Revolutionary | Minimalist | Evolutionary |
| **Educational Value** | Highest | High | Medium |
| **Tournament Ready** | Experimental | No | Yes |

## Known Limitations

1. **Tactical Horizon Effects**: No quiescence search means can miss captures
2. **Weak Opening Play**: No opening knowledge or strategic understanding
3. **King Safety**: May expose king to attacks
4. **Repetition Blindness**: Can't detect or avoid draw by repetition
5. **Positional Weakness**: Limited understanding of pawn structures
6. **No History**: Doesn't learn from searched positions

## Future Possibilities

Potential enhancements (in order of priority):

1. **Minimal Quiescence** (1-2 ply) - Reduce tactical blindness
2. **Repetition Detection** - Avoid draw loops  
3. **Endgame PST** - Better king activity
4. **Null Move Pruning** - 20-30% speedup
5. **Tiny TT** (1000 entries) - Catch repetitions

*Note*: Adding too much defeats the purpose!

## Development

### Running Tests

```bash
# Performance comparison
python testing/test_vpr_comparison.py

# Quick functionality test
python -c "
import sys
sys.path.insert(0, 'src')
from vpr import VPREngine
import chess

engine = VPREngine()
board = chess.Board()
move = engine.search(board, time_limit=2.0)
print(f'‚úì Engine works! Best move: {move}')
print(f'Nodes: {engine.nodes_searched:,}')
"
```

### Testing with Arena GUI

1. Open Arena Chess GUI
2. Add engine: `python /path/to/vpr_uci.py`
3. Set engine name: "VPR v1.0"
4. Play or analyze!

### Debugging

Enable verbose output in `vpr.py`:

```python
# In _negamax(), add:
if depth > 0 and self.nodes_searched % 10000 == 0:
    print(f"info string depth={depth} nodes={self.nodes_searched}")
```

## Contributing

VPR is intentionally minimal. Contributions should:
- Maintain simplicity (avoid feature creep)
- Improve speed without adding complexity
- Fix bugs without adding overhead
- Enhance documentation

## License

Same license as V7P3R (see main repository).

## Credits

- **Author**: Pat Snyder
- **Based on**: V7P3R Chess Engine
- **Inspiration**: Simple chess engines (Sunfish, TSCP, etc.)

## FAQ

**Q: Why is it called VPR?**  
A: VPR stands for "V7P3R" with the vowels removed - representing both the stripped-down nature of v1.0 and the revolutionary rethinking of v7.0.

**Q: Is VPR v7.0 stronger than V7P3R?**  
A: Different, not necessarily stronger. VPR v7.0 thinks like a human and excels in certain areas (endgames, piece analysis) but V7P3R has deeper search and more mature evaluation. VPR v7.0 is about exploring **how** an engine thinks, not just strength.

**Q: What's VPR's ELO rating?**  
A: 
- **VPR v7.0**: Estimated 1400-1700 (human-like tactical awareness)
- **VPR v1.0**: Estimated 1200-1500 (strong calculation, weak evaluation)

**Q: Should I use VPR in tournaments?**  
A: VPR v7.0 is experimental - use V7P3R v12.x for serious play. VPR is for learning and research into human-like chess thinking.

**Q: Can I add [feature X]?**  
A: For VPR v7.0, consider if it maintains the human-like thinking paradigm. For VPR v1.0, consider if it aligns with maximum simplicity. Fork for heavy modifications!

**Q: Why no static piece values in v7.0?**  
A: This is VPR v7.0's revolutionary innovation - pieces are valued entirely by what they can accomplish in the current position, just like human players think.

**Q: What's the biggest difference between v1.0 and v7.0?**  
A: 
- **v1.0**: "How fast can I search?" (speed-focused)
- **v7.0**: "How should I think?" (cognition-focused)

**Q: Which version should I study?**  
A: 
- **Study v1.0** for: Understanding minimal engines, speed optimization, basic algorithms
- **Study v7.0** for: Human-like AI, piece-centric thinking, dynamic evaluation innovation

**Q: How much stronger could VPR v7.0 be with traditional optimizations?**  
A: Adding transposition tables, quiescence search could improve strength, but might compromise the human-like thinking approach. The goal is cognitive innovation, not just ELO points.

---

**VPR v7.0** - Revolutionary Human-Thinking Engine  
*The first engine to think about pieces, not moves.*

**VPR v1.0** - Experimental Maximum Depth Engine  
*When you absolutely, positively need to see 8 plies deep.*
